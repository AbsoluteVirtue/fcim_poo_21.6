# Data-oriented design
Развитие сферы реляционных баз данных дало толчок к появлению набора специфических техник программирования, которые принято называть общим термином "проектирование, ориентированное на данные". Необходимость такого подхода в программировании можно выразить цитатой Никлауса Вирта,
> Программное обеспечение становится медленнее с большей скоростью, чем процессоры становятся быстрее.

Ориентинование на данные,в первую очередь, стало популярным среди разработчиков систем, работающих "реальном времени" -- т.е. это такие системы, для которых отклик на любые события должен происходить за очень короткий (измеряемый в миллисекундах) промежуток времени. Такими системами являются, например, операционные системы, работающие на борту самолета, системы управления баллистическими ракетами, компьютерные игры и т.п.
## Быстродействие программ
Для таких систем есть несколько критически важных свойств, которыми они должны обладать. Ниже приведена неполная таблица различных операций на современных процессорах.

|операция|кол-во тактов|секунды
|--|--|--
|простейшая операция на регистрах (add, or, move)|до 1|10<sup>-9</sup>
|"угаданный" if|1-2|
|сложение векторов|1-3|
|умножение|1-7|
|чтение из кэша первого уровня|3-4|
|чтение из кэша второго уровня|10-12|10<sup>-8</sup>
|"неугаданный" else|10-20|
|деление векторов|10-70|
|целочисленное деление|15-40|
|вызов функции в языке С|20-50|
|вызов виртуальной функции в С++|30-60|
|чтение из кэша третьего уровня|30-70|
|чтение из оперативной памяти|100-150|10<sup>-7</sup>
|динамическое выделение памяти для маленьких объектов|200-500|
|системный вызов ядра ОС (может случиться при динамическом выделении)|1000-1500|10<sup>-6</sup>
|переключение контекста потоков|2000|
|пойманное "исключение"|3000-10000|10<sup>-5</sup>

Это приблизительные значения, и приводятся они только для того, чтобы отметить, что некоторые операции занимают на порядки больше времени, чем простейшие операции. Из этого можно сделать вывод, что арифметические операции, например, эффективнее, чем сохранение их результата в переменную, что может не быть очевидным. Динамическое выделение памяти может занять 1000 циклов процессора, поэтому если память выделяется в цикле несколько раз, это значительно замедлит систему. И отсюда же понятно, почему разработчики С++ не советуют использовать исключения там, где это не является критической необходимостью.

К этому можно добавить тот факт, что процессоры современных архитектур быстрее уже не станут, так как единственное, что можно в них повышать, это количество транзисторов-ядер, а значит выигрыш в производительности может быть достигнут только засчет параллельного программирования. Поэтому так важно внимательно следить за тем, сколько памяти потребляет программа во время работы, сколько данных одновременно передается на процессор, и какие именно данные. Из таблицы выше видно, что самые быстрые операции -- те, которые могут использовать данные из кэша первого или второго уровня. Причем, емкость этих кэшей сильно ограничена. И напротив, работа с основной памятью занимает много времени, а большинство "традиционных" техник программирования предполагает неограниченное выделение объектов в основной памяти.
## Трюки для ускорения программ
До недавних пор компиляторы языков программирования вроде С и С++ были сравнительно простыми и не делали с исходным кодом тех вещей, которые сегодня делаются автоматически (например код, написанный программистом, может быть удален компилятором или сильно модифицирован, если компилятор определит, что это положительно повлияет на работу программы). В прошлом программисты вынуждены были прибегать к различным хитростям для того, чтобы выжать из процессора все, что можно.

	long i;
	float x2, y;
	const float threehalfs = 1.5F;
	x2 = number * 0.5F;
	y  = number;
	i  = * ( long * ) &y;
	i  = 0x5f3759df - ( i >> 1 ); 
	y  = * ( float * ) &i;
	y  = y * ( threehalfs - ( x2 * y * y ) );
Выше приведен пример алгоритма взятия обратного квадратного корня числа, который используется для нормализации векторов в различных системах. Реализация интересна тем, что использует метод Ньютона, причем, применяется побитовая арифметика вместо умножения и деления. Двадцать лет назад использование этого алгоритма позволило сэкономить примерно 30 тактов процессора. Сегодня писать такой алгоритм смысла не имеет, так как компилятор содержит правила преобразования кода, которые подбирают лучшую комбинацию инструкций для каждого случая.

Например, умножение целых чисел принято реализовывать через сложение и побитовые сдвиги результата, если число является степенью двойки.

    // x * 522
    int x;
    x = (x << 9) // 512
      + (x << 3) // 8
      + (x << 1) // 2
    ;
Несмотря на то, что двадцать лет назад такое решение было бы оптимальным, компилятор gcc удалит весь этот код и подставит другую реализацию: imul eax, edi, 522. То есть, он заменяет "эффективные" операции сложения на одну операцию умножения, т.к. на современных архитектурах одна операция умножения сравнительно быстрее цепочки операций сложения.
## Работа с памятью
Примеры выше показали, что бороться за производительность на уровне инструкций в современных системах не так практично. Комбинация передовых процессорных команд и современных стратегий оптимизации, применяемых в компиляторах, делает последующую оптимизацию отдельных инструкций кода ненужной. На первый план выходят проектирование алгоритмов и композиция данных в структурах.

    int a;  struct { int a; };               // 4, 4
    bool b; struct { bool b; };              // 1, 1
    union  { int a; bool b; }                // 4, 4
    struct { int a; bool b; }                // 4, 8
    struct { int a; double d; int b; }       // 8, 24
    struct { int a; int b; double d; }       // 8, 16
    struct { int a; int b; int *p; bool b; } // 8, 24
Пример выше описывает использование памяти различными структурами в языке С. Здесь важно отметить, что если обычные переменные занимают строго столько памяти, сколько определено платформой (например, 4 байта для int, 1 байт для bool), для структур правила немного другие. Структура должна быть выровнена по самому большому полю, поэтому тип данных, комбинирующий типы int * bool, занимает не 5 байтов, как можно было бы подумать, а 8 (лишние три байта просто не могут быть использованы). По этой же причине структура int * double * int занимает больше места, чем int * int * double. В обоих случаях выравнивание будет по 8 байтов, но если наибольший тип "зажат" между двумя меньшими типами (4-8-4), система будет вынуждена выделять места достаточно под три 8-байтовых значения, чтобы сохранить выравнивание. Если же два поля int идут одно за другим (4-4-8), они оба помещаются в 8 байтов сразу за полем типа double.

Из этого простого правила можно вывести на удивление много правил, которые позволяют значительно сократить количество потребляемой программой памяти.
### Кодирование информации вне структуры
В качестве первого примера будет рассмотрена структура,

    struct s { int x; bool b; };
с помощью которой необходимо объявить массив из 100 объектов такого типа.

    s arraylist[100] = {};
    for (unsigned i = 0; i < 100; ++i)
        if (arraylist[i].b) // объект принадлежит первой категории
        else                // объект принадлежит второй категории
Если проверить размер этого массива, можно ожидать, что он составит 800 байтов ((4 + 4) * 100). Здесь можно заметить, что булевое поле, храня 1 бит информации, вынужденно занимает 4 байта, то есть, в массиве почти половина всей памяти никогда не используется (каждое булевое значение, находясь в такой структуре, тратит 31 бит впустую). Правильное решение в такой ситуцайции не сразу очевидно. Если как-то нужно пометить объекты, которые принадлежат одной из двух возможных категорий, булевое поле напрашивается само собой.

Идея решения в том, что сама структура не обязательно должна хранить эту информацию в индивидуальном порядке. Намного проще изначально разделять все объекты на две категории, сделав два подмножества, тогда статус или вид конкретного объекта очевиден, исходя из того, какому подмножеству он принадлежит.

    struct s { int x; }
    s a_list[50] = {};     // объекты первой категории
    s b_list[50] = {};     // объекты второй категории
    for (unsigned i = 0; i < 50; ++i) a_list[i].a
    for (unsigned i = 0; i < 50; ++i) b_list[i].a
В новой конфигурации производительность будет значительно лучше, потому что количество итераций по спискам не изменилось, но пропала необходимость булевой проверки (а значит -- альтернативного прыжка, который трудно предсказать). При этом, информация в программе сохранилась, но она более плотно расположена в памяти, что позволит процессору обработать ее всю за меньшее количество тактов.
> From a database perspective, the out-of-band method is like normalizing your data with foreign key indexes.

### Относительная и абсолютная адресация
Сама суть адресации в программах уже должна быть любому читателю знакома. Адрес ассоциируется с беззнаковым числом, которое гарантированно будет уникальным, используя которое можно прочитать или изменить значение в памяти. Адреса, как правило, хранятся в указателях.

    int x = 42;
    int *p = &x;
Банальный пример взаимодействия с указателем показан выше. Адрес переменной *x* можно сохранить в переменной *p*, которая является ссылкой на значение переменной *x*. Работа с самим указателем теперь требует использования специальных операторов. Например,

    *p = 0;
обнуляет значение переменной *x*, потому что унарный оператор * позволяет обратиться к значению по конкретному адресу. Такой способ работать с адресами не часто применяется, так как нужно учить специальные правила. Вместо этого применяется альтернативный подход.

    int a[100];
    unsigned i = 0; // handle
    a[i] = 42;
Ситуация, аналогичная предыдущей, использует индекс для обращения к конкретному значению в памяти вместо указателя. Здесь с помощью массива резервируется блок адресов, и соответственно, можно использовать натуральные числа в комбинации с операторами для работы с массивами, чтобы упростить запись. В этих примерах переменная *p* хранит абсолютный адрес (абсолютный с точки зрения программы, так как он уникален в контексте процесса), а переменная *i* -- относительный (так как он вычисляется относительно другого адреса, в данном примере -- *а*).

Кроме простоты записи здесь есть и другое полезное следствие. Относительный адрес может хранить меньше данных при равном объеме информации. Если абсолютные адреса обязаны быть самыми большими числами на платформе (обычно соответствуют ширине "шины"), то размер относительного адреса определяется, исключительно исходя из надобностей программы и ограничен только ее имманентными свойствами. В примере выше указатель p обязан хранить 8 байт на 64-битной платформе, даже если не все эти байты нужно использовать. Дескриптор (handle) i является 4-байтовым значением, так как в программе не нужно большее количество относительных адресов.

    struct s { 
        String *a; 
        String *b; 
    } str = { .a=malloc(sizeof(String)),
              .b=malloc(sizeof(String)),
    };
Данный пример содержит структуру, которая осуществляет доступ к двум строкам: *a* и *b*. Не так важно, как именно обе строки конструируются, после этого к ним можно обращаться как к обычному тексту.

    printf("%s %s", str.a, str.b);
Сама структура будет занимать 16 байтов.

    struct s { 
        unsigned a; 
        unsigned b; 
    } str = { .a=0, .b=1, };

    char *n[2];
    printf("%s %s", n[str.a], n[str.b]);
В новой версии структуры её поля *a* и *b* выполняют роль относительных указателей, поэтому сама структура занимает в два раза меньше места в программе (4 + 4 = 8 байтов). Использование такой структуры отличается от прошлой версии только косметически.
### Structure of Arrays
    enum v { fast, slow };

    struct s { char *a; v b; }; // sizeof(s) == 16

    s arraylist[100] = {};
Структура в этом примере включает в себя указатель и целое число, но здесь важны не столько типы данных полей, а то, что они разных размеров. Выравнивание полей структуры опять приводит к тому, что четверть всей памяти будет пустовать. Это особенно важно в ситуациях, когда структуру необходимо создавать многократно (например, инициализировать массив). Массив из 100 элементов будет занимать 1600 байтов. 

    struct s { char *as[100]; v vs[100]; }; // sizeof(s) == 800 + 400

    s multiarray = {};
Второй пример является аналогом первого примера, но это не сразу очевидно. Повторяется приём с сохранением информации и одновременным сжатием данных в структуре. Вместо того, чтобы создавать массив структур, в котором четверть всей памяти не может быть использована, можно создать структуру, в которой поля имеют те же типы данных и расположены в том же порядке, но сами являются массивами. В обоих случаях пользовтелям будет доступно 100 строк и 100 целых чисел, но в первом примере -- в рамках общего массива, а во втором -- в двух отдельных массивах. 

    for (unsigned i = 0; i < 100; ++i) arraylist[i].a; arraylist[i].v;
    // против
    for (unsigned i = 0; i < 100; ++i) arraylist.as[i]; arraylist.vs[i];
Таким образом, структуру не придется выравнивать по одному из полей, так как все данные запакованы в соответствующих массивах. Массив из 100 строк будет занимать 800 байтов, а массив из целых чисел -- 400 байтов, что в сумме дает 1200 - то есть, на 25% меньше, чем первоначальный "смешанный" массив. Разница между двумя структурами во время использования косметическая.
### Hash table vs sparse array 
Существует еще одна категория структур, которая имеет тенденцию к созданию лишних байтов, которые никогда не будут использованы в программах. Например,

    struct s { int a; int b; int list[4]; }; // sizeof(s) == 24

    s arraylist[100] = {};
Структура сождержит только целые числа, поэтому выравнивание не требуется, и ее размер будет равен 24 байтам. Массив таких структур из 100 элементов будет занимать 2400 байтов.

Проблемы с такой организацией данных могут возникнуть в случаях, когда массив *list* первоначальной структуры не используется на 100%. Если в программе, которая использует такую структуру -- например, в массивах -- есть тенденция к тому, чтобы не заполнять все элементы поля *list*, это уже приведет к потере 15%-60% памяти, которая опять будет пустовать. Предполагая, что какие-то из структур будут хранить в этом поле реальные данные, а какие-то -- нет, имеет смысл вынести это поле за пределы структуры. Для тех объектов структуры, которым это поле нужно, достаточно определить связь с внешним массивом нужного размера, а для тех объектов, которым оно не нужно, делать дополнительно ничего не придется. Для этих целей подойдет простая таблица, которая каждый объект структуры ассоциирует с заполненным массивом, если он есть.

    struct s { int a; int b; };              // sizeof(s) == 8

    s arraylist[100] = {};

    std::map<unsigned, int[4]> m = {};       // sizeof(m) == m.size() + [0, (20 * n)]
В новой версии параллельно массиву структур создается ассоциативный массив, в котором ключом будет индекс структуры, а значением -- массив из 4-х целых чисел, который раньше был внутри структуры. Таким образом, если отдельному объекту нужен массив, он может запросить его в таблице, и такой массив будет создан по запросу, только для тех объектов, которые его используют. В самом оптимальном случае использование памяти будет равно 800 байтам для 100 структур, вдобавок к пустой хэш-таблице. В худшем случае таблица будет состоять из 100 записей, данные которых будут составлять 400 байтов для ключей и 1600 байтов для 100 значений (800 + 400 + 1600 = 2800 байтов). Это чуть больше, чем в худшем случае для первоначального варианта структуры (2400 байтов), но само использование таблицы предполагает, что разработчик уверен в том, что в большинстве ситуаций 100 ключей и значений не понадобится.

    for(unsigned i = 0; i < 100; ++i) arraylist[i].list[0];
    // против
    for(unsigned i = 0; i < 100; ++i) m[i][0];
Что касается использования, не считая проверки наличия ключа в таблице, разница косметическая.

Промежуточные выводы из четырех примеров выше:
- следует облегчать процесс кэширования для процессора, что возможно благодаря более эффективному использованию памяти;
- данные следует группировать в зависимости от того, как производится доступ к данным (то, что часто читается вместе должно храниться вместе);
- инструкции тоже кэшируются: код, который используется реже (например, проверки *if* в теле цикла), стоит вызывать отдельно от кода, который исполняется часто;
- вместо массива структур часто лучше использвать структуру массивов.
## Практический пример
Ниже приведен пример "объектно-ориентированного" кода, аналогичные фрагменты можно найти в различных обучающих ресурсах.

    class Base { int a; int b; };

    class X : public Base {
        bool hidden; std::string id; bool special;
    public:
        std::function<void(std::string)> on_hide; // strategy pattern
        void update() {
            if (hidden) { on_hide(id); } 
            else if (get_config().SPEC || special) {...} else {...}
        }
    }; 
Класс наследуется от базовой реализации, содержит четыре дополнительных поля, включая вызываемый объект on_hide, который можно изменять при инстанциировании объекта. Метод update изменяет свойства объекта, здесь стоит обратить внимание на блок *if-else if-else*.

    using px = std::unique_ptr<X>;
Для того, чтобы сымитировать ООП-языки, которые используют сборщик мусора, объекты класса создаются на куче и оборачиваются в *unique_ptr*. С помощью цикла симулируется то, как похожие объекты используются в реальных проектах.

    std::vector<px> items; for (auto e : items) e.update();
В первую очередь стоит обдумать, какие части этого фрагмента похожи на проблемы из предыдущей части с примерами:
- самое большое поле типа std::string, которое также выделяется на куче;
- поля типа bool потенциально могут быть удалены;
- функция update потенциально будет вызываться в цикле, содержит дополнительные вызовы функций, а также ветвление.

Далее будет рассмотрено несколько способов оптимизировать данную структуру согласно рекомендациям из предыдущей части. Читателю советуется самостоятельно выполнить это упражнение, прежде чем смотреть решения, предложенные ниже.
### Свободные функции вместо методов
    struct Y : public Base {
        bool hidden; std::string id; bool special;
        std::function<void(std::string)> on_hide;
    }; 

    using py = std::unique_ptr<Y>;

    void update(const std::vector<py>& items) {
        for (auto e : items) {
            if (e.hidden) e.on_hide(e.id);
            else if (get_config().SPEC || e.special) {...} else {...}
        }
    }
Функция *update* играла роль сеттера, когда была методом класса, хотя использование этой функции предполагает последовательное обновление всех объектов данного типа, которые соответствуют какому-то критерию. Так как обновление единственного объекта происходит редко, функцию можно вынести из класса (сделать "свободной") и обновлять список объектов для большей эффективности. Из этого следует, что класс кроме полей с данными ничего не содержит. Имеет смысл заменить класс на структуру (паттерн "plain ol'data", https://wiki.c2.com/?PlainOldData), чтобы исключить излишние вызовы методов класса в неочевидных местах.
### Отсутствие вызовов "делегатов" в теле цикла
Другой тонкий момент, который проявляется в коде функции -- это вызов функции *on_hide*, которая параметризована (хранится как ссылка на функцию в структуре, делегирует вызов другой функции). Это значит, что в разных объектах могут храниться ссылки на разные функции, что очень плохо повлияет на поведение объектов в кэше процессора (не все функции могут находиться в кэше одновременно, поэтому если после выполнения вызова *on_hide* регулярно приходится обновлять ссылку, по которой делается вызов, это может значительно замедлить обработку в цикле).

Одним из возможных решений будет удаление подходящего объекта из списка вместо его скрытия. 

~~std::function<void(std::string)> on_hide;~~

~~if (e.hidden) e.on_hide(e.id);~~

    for (auto e : items) {
        if (e.hidden) items.erase(e); // observer pattern
        else if (get_config().SPEC || e.special) {...} else {...}
    }
Но если сделать это изменение необдуманно, можно внести в программу серьезную проблему: так как удаление происходит в цикле, который проходит по списку, из которого динамически удаляются элементы, цикл может потерять последний элемент списка. В примере выше конец списка является итератором вектора, а для вектора любое изменение состава может стать причиной перенести все оставшиеся элементы в другую область памяти. Это повлечет за собой инвалидацию итератора на конец вектора, так как он продолжит указывать на предыдущий блок памяти, валидный в начале цикла.

По этой причине контейнер в параметре функции необходимо изменить на другой тип. Одновременно можно избавиться от указателей на объекты, так как ввиду всех изменений динамическая память под каждый объект больше не приносит никакой пользы.

~~using py = std::unique_ptr<Y>;~~
   
    void update(std::list<Y>& items);
Это вносит другую проблему в программу. Данная функция теперь не безопасна для использования в многопоточных или многопроцессорных средах, так как два потока будут работать над одним и тем же списком в памяти. Строго говоря, параметр должен быть локальной копией, которая возвращается функцией после обработки, но это потребует дополнительных затрат на копирование в случае большого объема изначального списка.
### Мемоизация
В одном из условий внутри тела цикла проверяется наличие определенных данных в файле конфигуркции программы. Данные читаются не напрямую из файла, а из выражения, которое является десериализованными данными (например, объектом-синглтоном) -- с помощью геттера *get_config*. Можно заметить, что от итерации к итерации данные в файле настроек меняться, скорее всего, не будут, а если и будут, для процесса обновления это не имеет значения, так как достаточно, чтобы информация, на основании которой данные в списке должны быть отфильтрованы, была валидна в момент вызова функции *update* (т.е. в момент принятия решения об обновлении списка).

Это значит, что данные из настроек можно не запрашивать каждый раз, достаточно их проверить до начала цикла.

    auto is_special = get_config().SPEC;
    for (auto e : items) {
        if (e.hidden) items.erase(e); // observer pattern
        else if (is_special || e.special) {...} else {...}
    }
Переменная *is_special* хранит результат вызова *get_config*. В теле цикла значение переменной можно проверять без необходимости каждый раз вызывать функцию, так как последующие результаты не имеют значения в данном контексте. Такой способ запоминания результата вызова функции в целях оптимизации называется "мемоизацией".
### Реорганизация полей структуры
Несмотря на то, что структура является простым объектом с данными, использование ею памяти можно сократить, совершив элементарные манипуляции.

struct Y : public Base { ~~bool hidden; std::string id; bool special;~~ }; 

    struct Y : public Base {
        bool hidden; bool special; unsigned id;
    };
Первая попытка может выглядеть как показано выше. Поля типа *bool* стоит держать рядом, так как они смогут быть организованы в пустые байты структуры, которые останутся после выравнивания остальных полей.

Поле *id* изначально хранилось в виде строки. В целом, хранить информацию как строки без острой на это необходимости не особо эффективно. Строки имеют место в некоторых случаях. Например, если значение планируется часто показывать пользователям, и информация должна быть легко читаемой; в других ситуациях важно, чтобы возможных комбинаций значений было очень много, и десяти цифр не достаточно для ее кодирования; может потребоваться также часто переводить значения из одной кодировки в другую, а это легче делать на строках и т.п. В данном случае никакого выигрыша нет от того, что уникальный номер является строкой, поэтому его можно заменить на натуральное число.

Но даже после этих изменений есть один нюанс, который становится очевиден только при ближайшем рассмотрении. Поля *hidden* и *special* кодируют несколько вохможных состояний объекта:

|hidden|special|
|--|--
|false|true
|false|false
|true|true
|true|false

То есть, если объект не скрыт, важно также знать, является ли он особым или обычным. Если же объект скрыт, не имеет значения особый он или нет, так как проверять его не нужно. То есть, из четырех возможных состояний значение для программы имеют только три. Отсюда следует, что два булевых поля можно заменить на одно поле из перечисления вохможных состояний.

struct Y : public Base { ~~bool hidden; bool special;~~ unsigned id; };

    enum states { shown, shown_special, hidden };

    struct Y : public Base {
        states state; unsigned id;
    };
Это позволяет дополнительно оптимизировать функцию *update*.

for (auto e : items)
    ~~if (e.hidden) items.erase(e); else~~ 
    if (is_special || *e.state == shown_special*) {...} else {...}

Так как функция работает только с видимыми объектами, и для определения нужных объектов есть специальное состояние, проверять объект на скрытость нет необходимости, а следовательно и удаление объектов можно вынести за пределы цикла, значительно его ускорив. 

    items = items | std::ranges::filter( [](auto e){ return e.state != hidden; }) 
                  | std::views::to<std::list>();
Удаление можно провести с использованием диапазона вместо цикла *for*, чтобы дать компилятору возможность оптимизировать цепочку операций.
### Более подходящий контейнер
В данном примере можно заметить еще одну закономерность: порядок объектов в списке не имеет значения для функции *update*, потому что она успешно завершается, только если все объекты обновлены. Это дает еще одно потенциальное преимущество, удаление элементов можно упростить, если порядок не важен. Например, вместо метода erase или создания отфильтрованного нового списка с помощью диапазона, можно использовать последовательный перенос элемента в конец контейнера, для того, чтобы удалить его через *pop_back* или другой аналогичный метод.

Метод *erase* может выполняться за время O(1), если в момент вызова есть ссылка на удаляемый элемент, в противном случае время будет иметь линейную зависимость, О(n - i), где n - длина контейнера, а i - позиция удаляемого элемента. Метод *pop_back* почти всегда гарантированно будет O(1) даже в комбинации с *swap*, который тоже O(1).

~~items = items | std::ranges::filter( [](auto e){ return e.state != hidden; }) 
                  | std::views::to<std::list>();~~

    std::swap(e, *(items.end() - 1));
    items.pop_back();
В зависимости от сценария, типом контейнера items можно сделать *vector* или *priority_queue*, оба контейнера ранят элементы в одном блоке, поэтому это положительно повлияет на кэширование данных при обработке. Польза от использования *priority_queue* заключается в том, что он уже удаляет элементы через swap-back механизм, но за это придется заплатить вставкой, которая должна сохранять приоритетность элементов и в большинстве случаев не будет O(1), а в данном сценарии это излишне.
### Кодирование информации (out-of-band)
Отталкиваясь от последнего выбора контейнера, следующее изменение будет заключаться в переносе информации из структуры в способ обработки массивов таких структур. Можно было заметить, что алгоритм обновления всех объектов теперь состоит из трех явных этапов:
- обработка особых элементов
- обработка нормальных элементов
- обработка скрытых элементов.

Стратегии обработки для каждого элемента могут значительно отличаться. Следовательно, выбор стратегии можно делать еще до цикла, вынеся *if-else* из него. Но можно пойти дальше. Можно разделить все объекты на три отдельных списка вместо одного общего: список особых, список обычных и список скрытых -- и просто переносить из одного списка в другой по необходимости. Тогда для каждого списка будет индивидуальный способ обновления, который не зависит от остальных двух видов объектов.

    struct Y : public Base { unsigned id; };

    std::vector<Y> norm;   void update_norm  (std::vector<Y>&);
    std::vector<Y> spec;   void update_spec  (std::vector<Y>&);
    std::vector<Y> hidden; void update_hidden(std::vector<Y>&);
Наконец, последний неожиданный вывод, который можно сделать, заключается в ненадобности структуры *Y*, так как в ней кроме уникального идентификаторы больше нет полезных данных, а значит хранение структуры Base в определенном порядке позволит закодировать поле *id*, например, с помощью хэш-таблицы.

Закончить данную часть можно цитатой Александра Степанова,
> любители ООП думают, что все в программировании - это объект, что не совсем так. Есть вещи, которые являются объектами. Вещи, у которых есть состояние, и которые меняют свое состояние - это объекты. И есть вещи - не-объекты. Бинарный поиск - это не объект. Это алгоритм.